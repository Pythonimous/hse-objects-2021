{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom IPython.display import FileLink","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade torchvision","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nfrom torchvision import transforms\nfrom PIL import Image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = '../input/photos-for-object-detection/photos'\nexisting_file = '../input/picklebackups/img_objects.pickle'\nout_file = '../working/img_objects.pickle'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detection_model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(\n    pretrained=True, progress=True, num_classes=91, pretrained_backbone=True, trainable_backbone_layers=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detection_model.to(device).eval()\nprint(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_prediction(model, image, threshold):\n    \n    preds = model(image)[0]\n    \n    keep_boxes = torchvision.ops.nms(preds['boxes'], preds['scores'], 0.5)\n    \n    classes = list(preds['labels'].cpu().numpy())\n    classes = [classes[idx] for idx in keep_boxes]\n    boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(preds['boxes'].cpu().detach().numpy())]\n    boxes = [boxes[idx] for idx in keep_boxes]\n    scores = list(preds['scores'].cpu().detach().numpy())\n    scores = [scores[idx] for idx in keep_boxes]\n    \n    valid_boxes = [scores.index(x) for x in scores if x>threshold]\n    if not valid_boxes: return [()]\n    p_thresh = valid_boxes[-1]\n    pred_boxes = boxes[:p_thresh+1]\n    pred_classes = classes[:p_thresh+1]\n    pred_scores = scores[:p_thresh+1]\n    \n    return list(zip(pred_boxes, pred_classes, pred_scores))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImgDataset(Dataset):\n    def __init__(self, main_dir, transform):\n        self.main_dir = main_dir\n        self.transform = transform\n        self.all_imgs = os.listdir(main_dir)\n\n    def __len__(self):\n        return len(self.all_imgs)\n\n    def __getitem__(self, idx):\n        img_loc = os.path.join(self.main_dir, self.all_imgs[idx])\n        image = Image.open(img_loc).convert(\"RGB\")\n        tensor_image = self.transform(image)\n        return tensor_image, img_loc.split('/')[-1].split('.')[0], image.size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.isfile(existing_file):\n    found_objects = {}\nelse:\n    with open(existing_file, 'rb') as img_dict:\n        found_objects = pickle.load(img_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trsfm = transforms.Compose([transforms.ToTensor()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detect_dataset = ImgDataset(img_path, transform=trsfm)\ndetect_loader = DataLoader(detect_dataset, batch_size=1, shuffle=False, \n                               num_workers=0, drop_last=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = len(found_objects)\nfor img, imgname, imgsize in tqdm(detect_loader):\n    if imgname not in found_objects:\n        count += 1\n        img = img.to(device)\n        found_objects[imgname] = get_prediction(detection_model, img, 0.5)\n        if not count % 10000:\n            with open(out_file, 'wb') as img_dict:\n                pickle.dump(found_objects, img_dict, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(out_file, 'wb') as img_dict:\n    pickle.dump(found_objects, img_dict, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(r'img_objects.pickle')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}